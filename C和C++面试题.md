语言

### C++

##### 1、你在C++上的经历有哪些？

~~~
之前工作的时候项目里面有使用到C++,最近系统的学习了C++
~~~

##### 2、你对C++的新标准了解到了什么程度，17以后的内容？20，23？

~~~
C++11 auto_ptr弃用，C++11 以后引入两个关键字 [alignas]与[alignof]
C++20:
	支持协程(Coroutines（协程）:协程是一个可以记住自身状态，可随时挂起和执行的函数。) C++20引入了许多新特性，包括概念（Concepts）、三路比较操作符（Three-way Comparison）、协程（Coroutines）、范围（Ranges）、模块化编程（Modules）、时间日期库（Date and Time）、数字分隔符（Digit Separators）等。C++20还对已有特性进行了改进，如constexpr、模板元编程、元组、智能指针等。
C++17：https://cloud.tencent.com/developer/article/1979766
    1、[[nodiscard]] 属性:主要功能是可以让编译器在某个函数的返回值未被使用时进行告警，当然也可以不使用，或者使用后在后面的操作中也可以忽略这种警告
    2、[[maybe_unused]] 属性：可以抵消[[nodiscard]] 属性产生的效果，主要功能是避免编译器在某个变量未被使用时产生告警
    3、[[fallthrough]] 属性：主要功能是可以让编译器帮忙检查在switch语句中没有使用break时避免产生告警。
    4、[[deprecated]]属性：标记的值表示废弃
~~~



##### 3、指针和引用

```
1、指针是一个变量，存储的是一个地址，引用可以说是变量的别名，操作的时候就是操作变量本身
2、指针可以多级，引用只有一级
3、指针可以为空，引用一旦定义了必须初始化
4、指针可以改变指向，引用一旦初始化了就不能改变指向(被限制的指针)
	因为引用的本质就是指针常量，int &ref = a; 实际为 int * const ref = &a;
5、`sizeof`指针得到的是本指针的大小，`sizeof`引用得到的是引用所指向变量的大小
6、引用本质是一个指针，同样会占8字节(或者4字节)内存

```



##### 4、一般对C++的类来说，memory Layout有哪些成分？C++的对象在内存上的长什么样？

**内存布局**：

~~~
通常分为四个区：
栈区：存放函数运行分配的局部变量，函数参数，返回数据，返回地址等
堆区：new或者malloc申请的空间
全局数据区：全局变量，静态数据，和常量
代码区：类的成员函数(包括静态成员函数和非静态成员函数)和非成员函数代码存放在代码区

在类的定义时：
1、类的成员函数放在代码区
2、类的静态成员变量在全局数据区
3、非静态成员变量在类的对象内，对象在栈区或者堆区
4、虚函数指针和虚基指针在类的对象中，对象在栈中或者堆中
类的对象如果是定义的类局部变量，则在栈内存区，如果是new出来的类指针，则在堆内存区，同时引用会保存在栈里
	为何这样设计？其实这是从c语言发展而来的。类的成员变量相当于c的结构体，类的成员函数类似于c的函数，类的静态变量类似于c的静态或全局变量，至于虚函数，函数体还是放在代码区，但虚函数的指针和成员变量一起放在数据区，这是因为虚函数的函数体有多个，不同的子类调用同一虚函数实则调用的不同函数体，因此需要在类的数据区保持真正的虚函数的指针。
	类的静态成员函数所有对象共享
~~~



```
类的内存布局：
虚基指针(虚拟继承的情况)
虚函数指针（有虚函数的情况）
数据成员(静态数据成员不占用类的空间，在全局数据区，成员函数不占用类的内存空间，在代码区)

在内存上的长什么样：
按照声明的顺序在内存中有序排布，并适当对齐（对齐标准一般按照最大的成员变量来确定，可以用其中`alignof`可以计算出类型的对齐方式，`alignas`可以指定结构体的对齐方式）
如果有虚函数指针，虚函数指针就放在最前面
```



##### 5、如果对象涉及到继承呢？

~~~
继承基类的数据成员
派生类的数据成员
~~~



##### 6、父类转子类安全吗？子类转父类安全吗？

- 向上转型：子类转换为父类，安全

- 向下转型：父类转化为子类，不安全，会访问越界

  

##### 7、具体说一下虚继承是什么状态

```
派生类继承基类的时候添加一个virtual关键字，虚基类类的成员布局就只有一份，继承自虚基类的子类都有一个虚基指针，指向自己的虚基表，虚基表中存放的是虚基指针到虚基类类成员的偏移，这样就不会菱形继承的二义性
```



##### 8、假设一个类继承了有虚函数的类，父类会存在在子类中吗？

~~~
父类的数据成员会拷贝一份到子类中，成员函数共享，如果有虚函数，则子类会继承父类的虚函数指针，也会继承父类的虚函数表(复制过来的，父类的副本)，如果子类重写了虚函数，则会将虚函数表中的虚函数入口地址覆盖
~~~



##### 9、一个空类占多大内存？如果这个类包含了一个虚函数呢?假设是64位的机器呢？如果一个类继承了空类，大小是多少？

~~~
空类占据1个字节，起占位作用
包含了虚函数就有一个虚函数指针，64位系统下是8个字节大小
如果一个类继承了空类，大小是派生类自己的大小，继承空类的空类大小仍然是1个字节
~~~



##### 10、虚表里除了虚函数地址，还可能有什么？

~~~
虚表里不止是虚函数的入口地址，还有表头等信息，但是传递时地址从第一个虚函数算起。把虚表看成虚函数入口地址的数组，假设虚函数指针为void (*)()。还有可能有指针的偏移，不一定存的是虚函数入口地址
~~~

##### 11、如果一个函数是成员模板函数，可以被声明为虚函数吗？

~~~
不能
编译器在编译一个类的时候，需要确定这个类的虚函数表的大小。一般来说，如果一个类有N个虚函数，它的虚函数表的大小就是N，如果按字节算的话那么就是4*N。 
如果允许一个成员模板函数为虚函数的话，因为我们可以为该成员模板函数实例化出很多不同的版本，也就是可以实例化出很多不同版本的虚函数，那么编译器为了确定类的虚函数表的大小，就必须要知道我们一共为该成员模板函数实例化了多少个不同版本的虚函数。显然编译器需要查找所有的代码文件，才能够知道到底有几个虚函数，这对于多文件的项目来说，代价是非常高的，所以才规定成员模板函数不能够为虚函数。 
~~~



##### 12、inline关键字，（17之后的新标准）

```
	这个关键字用于告诉编译器在编译时尝试将函数或代码段直接插入到调用它的地方，而不是生成一个函数调用。这样做有助于减少函数调用的开销，特别是对于较小的函数，同时也可以提高程序的执行速度。然而，inline 只是一个建议，编译器不一定会将函数内联，具体是否内联由编译器决定。

 	inline 变量, inline变量可以让变量有多于一次的定义。C++17之前，我们定义全局变量，总需要将变量定义在cpp文件中，然后在通过extern关键字来告诉编译器 这个变量已经在其他地方定义过了。inline变量出现后，我们可以直接将全局变量定义在头文件中，而不用担心出现redefine的错误信息。
```



##### 13、虚函数可以内联吗？

~~~
	虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。
	内联是在编译期建议编译器内联，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时（运行期）不可以内联。
	inline virtual 唯一可以内联的时候是：编译器知道所调用的对象是哪个类，这只有在编译器具有实际对象而不是对象的指针或引用时才会发生。
~~~



##### 14、虚函数，虚函数调用开销，不用虚函数如何实现多态

- 空间开销：每个有虚函数的类都各自有一个虚函数表，每个类的实例对象都有一个虚函数指针，指向虚函数表
- 时间开销：主要是增加了一次内存寻址，通过虚函数表指针找到虚函数表，虽对程序性能有一些影响，但是影响并不大。
- 函数间接调用：普通函数调用是一个直接调用。直接调用与间接调用的区别就是跳转地址是否确定，直接调用的跳转地址是编译器确定的，而间接调用是运行到该指令时从寄存器中取出地址然后跳转。https://zhuanlan.zhihu.com/p/40546963
- 不用虚函数实现多态：静态多态：函数重载，运算符重载，模板

##### 15、optional<bool>取size是多大

~~~
std::optional对象只是包含对象的内部内存加上一个布尔标志。因此，大小通常比包含的对象大一个字节
bool类型为1个字节，optional<bool>为2个字节
~~~



##### 16、描述一下C++编译的整个过程

~~~
1、预处理阶段
将源代码中的预处理指令(如#include、#define等)处理后生成新的代码文件，同时生成一个名为“编译指令”的文件。也就是说处理以#开头的指令。
2、编译阶段
将经过预处理后的代码文件(如.cpp文件)翻译成汇编代码(.s文件)，由编译器完成。编译器进行语法分析、语义分析等操作并且产生符号表。也就是将.cpp文件转换为汇编文件(.s）。
3、汇编阶段
将汇编代码翻译成机器可以执行的二进制代码（.o文件），由汇编器完成。汇编器依赖符号表中的信息来处理变量名和函数名，并将它们转化成地址。
4、链接阶段
汇编程序生成的目标文件，即.o文件，并不会立即执行，因为可能出现.cpp文件中的函数引用了另一个.cpp文件中定义的符合或者调用了某个库文件中的函数。那链接的目的就是将这些文件对应的目标文件连接成一个整体，从而生成可执行的程序.exe文件。
~~~



![image-20240312205500669](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20240312205500669.png)

##### 17、对静态库和动态库的理解

```
二者的不同点在于代码被载入的时刻不同。
静态库的代码在编译过程中已经被载入可执行程序,因此体积比较大。
动态库(共享库)的代码在可执行程序运行时才载入内存，在编译过程中仅简单的引用，因此代码体积比较小。
不同的应用程序如果调用相同的库,那么在内存中只需要有一份该动态库(共享库)的实例。
静态库和动态库的最大区别,静态情况下,把库直接加载到程序中,而动态库链接的时候,它只是保留接口,将动态库与程序代码独立,这样就可以提高代码的可复用度，和降低程序的耦合度。
静态库在程序编译时会被连接到目标代码中，程序运行时将不再需要该静态库。
动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入，因此在程序运行时还需要动态库存在
```



##### 18、如果头文件定义了函数，源文件不实现，会在哪个环节报错？如果构建的是静态库，会报错吗？为什么？动态库呢？为什么？

 会在链接的时候报错，链接的时候找不到函数定义，静态库的话也会，链接的时候找不到

![image-20240312212225231](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20240312212225231.png)



![image-20240312215020468](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20240312215020468.png)

 动态库也一样，链接的时候找不到函数实现：

​	g++ -c -fpic test.cc

​	g++ -shared test.o -o libtest.so

![image-20240312220015364](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20240312220015364.png)





##### 19、stl中的智能指针有哪些？一个shared_ptr大小是多大？使用时如何决定使用哪个智能指针？

-  auto_ptr(c++11已经丢弃)

-  unique_ptr：独占式指针，只有一个指针能后指向该对象。不允许拷贝和赋值，具有移动语义，可以std::move过后作为容器的元素

-  shared_ptr：共享式指针，可以复制和赋值，多个指针指向同一个对象，最后一个指针被销毁时，这个对象才会被销毁。引用计数实现

-  weak_ptr：是辅助shared_ptr指针工作的，弱引用智能指针，不会增加引用计数，解决循环引用问题(可能会造成循环引用的问题)

-  shared_ptr的大小：16个字节(64位机器)

  ​	一个 shared_ptr 类型的变量包含了 2 个指针，weak_ptr 的尺寸和shared_ptr尺寸一样大，是裸指针的2倍。
  裸指针在32位机器上是4字节， 64位机器上是8字节
  weak_ptr和shared_ptr 在32位机器上占8字节 ， 两个裸指针大小
  第一个裸指针 指向的是这个智能指针所指向的对象
  第二个裸指针 指向一个很大的数据结构（控制块），这个控制块里有

  ​	1、所指对象的强引用计数

  ​	2、所指对象的弱引用计数

  ​	3、其他数据，比如自定义的删除器的指针等等。

  ![image-20240312231416218](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20240312231416218.png)



##### 20、unique_ptr取sizeof是多大？不同智能指针在性能上有什么区别?如果只是用指针解引用，性能上的区别呢?

- unique_ptr 和裸指针的大小一样，64位系统下是8个字节
- 相比于裸指针，智能指针利用`RAII`机制可以有效地防止内存泄露，更安全，所以如果不考虑性能与兼容性的场景优先使用智能指针。
- `std::unique_ptr` 相比于祼指针，它的性能损失几乎可以忽略，与祼指针的性能几乎相同的，所以更多时候建议优先使用`std::unique_ptr`，唯一的缺点就是需要开发者自己控制对象所有权的转移。（创建unique_ptr优先通过使用**make_unique**，自定义删除器只能使用直接构造的方式）
- unique_ptr它没有引用计数和线程安全的方法，所以它的性能其实比shared_ptr要高，但是不适用无序的多线程环境.
- `std::shared_ptr`， 由于它存在引用计数，并且对引用计数的增减是原子操作，在多线程场景下存在着性能开销，性能损失比较大，对性能敏感场景，不建议使用。 它的好处是开发者不需要管所有权的问题，自动管理。
- 一般优先使用**make_shared**来构造智能指针，更加高效。因为shared_ptr构造函数会执行两次内存分配，一次给int对象，一次给引用计数（可能还是两个内存区域）。而make_shared只会执行一次内存分配，将两个数据一次性分配完（一个内存区域）。https://developer.aliyun.com/article/1421255

只是解引用的话应该没有什么区别



##### 21、智能指针unique_ptr的应用场景

```
如果希望只有一个智能指针管理资源或者管理数组就用unique_ptr，如果希望多个智能指针管理同一个资源就用shared_ptr。
```



##### 22、删除父类指针可能有什么问题，怎么解决，除了虚函数呢？

~~~
base *pBase = new derived;
cout << "---" << endl;
delete pBase;
~~~

会导致子类的析构函数没有调用，没有释放子类的部分，通过将父类的析构函数设置为虚函数解决

如果将基类的析构函数声明为虚函数时, 由该基类所派生的所有派生类的析构函数也都自动成为虚函数. 即使派生类的析构函数与其基类的构造函数名字不相同.

C++的类中，构造函数用于初始化对象及相关操作，构造函数是不能声明为虚函数的，因为在执行构造函数前对象尚未完成创建，虚函数表还不存在。

析构函数则用于销毁对象完成时相应的资源释放工作，析构函数可以被声明为虚函数。在继承层次中，基类的析构函数一般建议声明为虚函数。



##### 23、C++多线程中常用的mutex是怎么实现的，和自旋锁(spin lock)有什么区别？

~~~
 实现原理上来讲，Mutex属于sleep-waiting类型的锁。
 例如在一个双核的机器上有两个线程(线程A和线程B)，它们分别运行在Core0和 Core1上。假设线程A想要通过pthread_mutex_lock操作去得到一个临界区的锁，而此时这个锁正被线程B所持有，那么线程A就会被阻塞 (blocking)，Core0 会在此时进行上下文切换(Context Switch)将线程A置于等待队列中，此时Core0就可以运行其他的任务(例如另一个线程C)而不必进行忙等待
 而Spin lock则不然，它属于busy-waiting类型的锁。

自旋锁是一种非阻塞锁，也就是说，如果某线程需要获取自旋锁，但该锁已经被其他线程占用时，该线程不会被挂起，而是在不断的消耗CPU的时间，不停的试图获取自旋锁。
互斥量是阻塞锁，当某线程无法获取互斥量时，该线程会被直接挂起，该线程不再消耗CPU时间，当其他线程释放互斥量后，操作系统会激活那个被挂起的线程，让其投入运行。
~~~



##### 24、atomic内部实现？是有锁还是没有锁的?所有的原子变量都没有锁吗？对原子变量的内存序（memory order）有了解吗?

~~~
原子操作是通过指令提供的支持，因此它的性能相比锁和消息传递会好很多。相比较于锁而言，原子类型不需要开发者处理加锁和释放锁的问题，同时支持修改，读取等操作，还具备较高的并发性能，几乎所有的语言都支持原子类型。可以看出原子类型是无锁类型
~~~

 atomic：原子操作是由底层硬件支持的一种特性

~~~
我们先来看看不使用原子操作的时候，我们会遇到什么问题。我们知道increase一个变量，CPU微观指令级别分成3步操作。
1) 先read变量的值到CPU内存寄存器；
2) 对寄存器的值递增；
3) 将寄存器的值写回变量
~~~

- 内部实现：

  ```
  第一种方法：bus lock：当CPU发出一个原子操作时，可以先锁住Bus（总线）。这样就可以防止其他CPU的内存操作。等原子操作结束，释放Bus，这个方法可以实现原子操作，但是锁住Bus会导致后续无关内存操作都不能继续
  第二种方法：Cacheline Lock：cpu0发出read信号后->将cache line设置为locked ->然后cpu0读取原子变量，修改，写入cache line -> 将cache line置位unlocked，cacheline是维持一致性的一种硬件策略方法。相当于是硬件对原子操作的一种实现方法。
  借助多核Cache一致性协议可以很方便实现原子操作。
  https://zhuanlan.zhihu.com/p/115355303
  ```

- 是没有锁的，通过指令操作实现的



##### 25、volatile，CAS，memory_order

~~~
volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等；。因此，遇到这个关键字声明的变量，编译器对访问该变量的代码就不能再进行优化，从而可以提供对特殊地址的稳定访问。声明时语法：int volatile vInt; 当要求使用 volatile 声明的变量值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。而且读取的数据立刻被保存。https://v1otusc.github.io/2021/05/20/C++_Volatile_%E5%85%B3%E9%94%AE%E5%AD%97/
一般说来，volatile 用在如下的几个地方：
    1、中断服务程序中修改的供其它程序检测的变量需要加 volatile；
    2、多线程间被几个任务共享的变量；
    3、状态寄存器一类的并行设备硬件寄存器，因为每次对它的读写都可能有不同的意义。
~~~

~~~
CAS：对比交换原理，CAS是一个原子指令，用于在多线程环境中实现同步。它将一个内存位置上的内容与一个给定的值进行比较，只有它们相同时才将该内存位置的内容修改为新的给定值。这个过程是作为单个原子操作完成的。 原子性保证了了这个新值是最新的，意思是说这个新值在被读取后到操作完成这个过程中不会被其它线程修改； 如果与此同时该值已被另一个线程更新，则写入将失败。 操作的结果必须表明它是否执行了替换，或者说是否成功完成了这个操作

~~~

~~~~
memory order https://luyuhuang.tech/2022/06/25/cpp-memory-order.html
~~~~



##### 26、define a 100 + 200, 问a*10 = ?

```
100 + 200 * 10 = 2100
```



##### 27、逆波兰表达式

~~~
波兰表达式的写法为 (* (+ 1 2) (+ 3 4))，将运算符写在前面，因而也称为前缀表达式。
逆波兰表达式的写法为 ((1 2 +) (3 4 +) *)，将运算符写在后面，因而也称为后缀表达式。
波兰表达式和逆波兰表达式有个好处，就算将圆括号去掉也没有歧义。上述的波兰表达式去掉圆括号，变为 * + 1 2 + 3 4。逆波兰表达式去掉圆括号，变成 1 2 + 3 4 + * 也是无歧义并可以计算的。事实上我们通常说的波兰表达式和逆波兰表达式就是去掉圆括号的。

波兰表达式（前缀表达式），实际是抽象语法树的表示方式，比如中缀 (1 + 2) * (3 + 4) 编译时转成的抽象语法树为

     *
  /    \
 +      + 
/ \    / \
1  2  3   4 

逆波兰表示式，可用栈进行计算，天生适合于基于栈的语言。遇到数字就将数字压栈，遇到操作符，就将栈顶的两个元素取出计算，将计算结果再压入栈。
~~~



##### 28、模板的简单应用

~~~
函数模板：
template <typename T>
T add (T x , T y)
{
	return x + y;
}
类模板：
template <typename T1, typename T2>
class Test
{
public:
	Test(T1 name, T2 age);
private:
	T1 _name;
	T2 _age;
};

~~~



##### 29、堆与栈的应用

- 栈：栈是一种线性的数据结构，读取规则是先进后出。栈中的数据占用的内存空间的大小是确定的，便于代码执行时的入栈、出栈操作，并由系统自动分配和自动释放内存可以及时得到回收，相对于堆来说，更加容易管理内存空间。


- 堆：堆是一种树形数据结构，读取相对复杂。堆是动态分配内存，内存大小不一，也不会自动释放。栈中的数据长度不定，且占空间比较大。便于开辟内存空间，更加方便存储。
- 程序运行时，每个线程分配一个栈，每个进程分配一个堆。也就是说，栈是线程独占的，堆是线程共用的。此外，栈创建的时候，大小是确定的，数据超过这个大小，就发生stack overflow错误，而堆的大小是不确定的，需要的话可以不断增加。

##### 30、static关键字

~~~
静态成员变量（面向对象）: 静态成员变量是该类的所有对象所共有的,静态成员变量存储在全局数据区，静态成员变量必须初始化，而且只能在类体外进行；static 成员变量和普通 static 变量一样，编译时在静态数据区分配内存，到程序结束时才释放。如果不赋值，那么会被默认初始化，一般是 0。静态数据区的变量都有默认的初始值，而动态数据区（堆区、栈区）的变量默认是垃圾值。

静态成员函数（面向对象）：静态成员函数属于类本身，而不作用于对象，因此它不具有this指针，正因为它没有指向某一个对象，所以它无法访问属于类对象的非静态成员变量和非静态成员函数，它只能调用其余的静态成员函数和静态成员变量，出现在类体外的函数定义不能指定关键字static；静态成员不需要通过对象就能访问。＜类名＞::＜静态成员函数名＞

静态全局变量（面向过程）：该变量在全局数据区分配内存；未经初始化的静态全局变量会被程序自动初始化为0（自动变量的自动初始化值是随机的）；静态全局变量的作用域在当前文件，其他文件不可见

静态局部变量（面向过程）：静态局部变量一般在声明处初始化，如果没有显式初始化，会被程序自动初始化为0；静态局部变量始终驻留在全局数据区，直到程序运行结束。但其作用域为局部作用域，当定义它的函数或语句块结束时，其作用域随之结束；

静态函数（面向过程）：静态函数与普通函数不同，它只能在声明它的文件当中可见，不能被其它文件使用，其它文件中可以定义相同名字的函数，不会发生冲突；
~~~



##### 31、虚函数与纯虚函数

~~~
定义一个函数为虚函数，不代表函数为不被实现的函数。
定义他为虚函数是为了允许用基类的指针来调用子类的这个函数。
定义一个函数为纯虚函数，才代表函数没有被实现。
定义纯虚函数是为了实现一个接口，起到一个规范的作用，规范继承这个类的程序员必须实现这个函数。
虚函数：有函数体
纯虚函数：虚函数赋值为0；virtual  void print() = 0;
~~~



##### 32、封装继承多态

~~~
封装：class
继承：
class Dervied
: public Base
{};
多态：
	动态多态：虚函数，纯虚函数
	静态多态：函数重载（名字改编实现）、模板
~~~





##### 36、深挖一个C++程序从编译到可执行文件到运行的详细过程

~~~
预处理（替换头文件，和宏定义，条件编译，处理注释）：生成预处理文件 g++ -E
编译：生成汇编文件，语法分析、语义分析等操作并且产生符号表 g++ -S
汇编：生成.o文件（目标文件）g++ -c
链接：生成可执行文件 g++
~~~



##### 37、链接器的作用

- 在链接的时候，链接的主要工作是找到每个符号和函数的位置并将它们链接到一起，链接器可以将多个编译好的程序模块合并成一个可执行文件。链接器的作用相当于组装，将多个独立的目标文件组装在一起，使之成为一个可执行文件。通过链接器，我们可以将项目中的多个源文件以及库文件进行链接，生成与机器指令相对应的可执行文件

  ```
  （1）符号解析：在链接过程中，链接器会对所有的目标文件进行符号解析，将每个符号映射到一个地址上。
  （2）重定位：链接器还会对程序中的每个地址进行重定位，将其指向正确的地址。
  （3）排除无用代码：链接器会将程序中没有使用的代码进行排除，以减小可执行文件的大小。
  ```

  

##### 38、int数组和vector在什么情况下，谁更快，为什么

~~~
	数组是一段连续的内存空间，它的访问速度非常快。因为可以直接通过数组的下标来访问元素，编译器可以根据下标计算出元素的地址，从而实现快速的访问。另外，数组的空间是在编译时就确定的，因此在程序运行时不会发生动态内存分配，也就不存在额外的开销。
	vector是一个封装了动态数组的类模板，它的访问速度相对较慢。当使用vector的下标访问元素时，需要先进行下标越界检查（at有检查，[]访问没有），然后通过指针加上偏移量来访问元素。这个过程需要一些额外的开销，因此vector的访问速度比数组略慢一些。另外，vector的空间是动态分配的，因此在程序运行时需要进行内存分配和释放，这也会带来一些额外的开销。
	虽然vector的访问速度相对较慢，但是它具有动态扩展的特性，在实际开发中，vector更适合存储动态变化的数据，因为它可以根据需要自动扩展或缩小存储空间，而数组的长度是固定的。另外，C++11引入了右值引用和移动语义，可以有效减少vector的拷贝开销，使得vector的性能得到了进一步提升。
~~~



##### 39、vector底层有什么数据，string呢有什么

~~~~
 vector: (底层数据结构是数组，通过三个指针偏移来取到元素)
 _Tp*     _M_start;				指向开头
 _Tp*     _M_finish;			指向数据末下一个空间
 _Tp*     _M_end_of_storage;	指向总空间最后
我们在使用vector的时候要注意，在插入位置和删除位置之后的所有迭代器和指针引用都会失效，同理，扩容之后的所有迭代器指针和引用也都会失效。
string有一个字符串指针吧
~~~~



##### 41、了解std::move的机制吗，实现一个

强制转换，左值转换为右值

static_cast<T&&>(lvalue);		//不准确 

~~~
https://gukaifeng.cn/posts/c-stdmove-shi-xian-xiang-jie/index.html
~~~



##### 42、struct和class的区别

```
struct的成员默认是public的

class的成员默认是private的
```



##### 43、左值和右值

~~~~
左值：能够取地址
右值：不能取地址
左值引用是左值
右值引用本身可以是左值，可以进行取地址，(int &&rref = 10; &rref;)
右值引用本身也可能是右值（函数的返回参数是右值引用的情况）
int && func()
{
	return 10;
}
int main()
{
	&func(); //error
}
~~~~

##### 44、为什么父类的析构函数必须是虚函数？

~~~
如果析构函数不被声明成虚函数，那么编译器将实施静态绑定，在删除基类指针时，只会调用基类的析构函数而不会调用派生类析构函数，这样就会造成派生类对象析构不完全，造成内存泄漏。
~~~

##### 45、C++ 中的 new/delete 函数与 malloc/free 的区别？

~~~
malloc/free和new/delete的共同点是：都是从堆上申请空间，并且需要用户手动释放。不同的地方是：
malloc和free是函数，new和delete是操作符
malloc申请的空间不会初始化，new可以初始化
malloc申请空间时，需要手动计算空间大小并传递，new只需在其后跟上空间的类型即可，如果是多个对象，[]中指定对象个数即可
malloc的返回值为void*, 在使用时必须强转，new不需要，因为new后跟的是空间的类型
malloc申请空间失败时，返回的是NULL，因此使用时必须判空，new不需要，但是new需要捕获异常
申请自定义类型对象时，malloc/free只会开辟空间，不会调用构造函数与析构函数，而new在申请空间后会调用构造函数完成对象的初始化，delete在释放空间前会调用析构函数完成空间中资源的清理
~~~

##### 46、使用 new 申请内存失败会怎么样？

```
会抛出异常。malloc会返回NULL
```

##### 47、如果我想使得申请失败后返回一个空指针，需要怎么做？

```
使用 nothrow new 来申请内存。
```



## linux 

#### 1、描述一下cpu怎么从内存中获取数据的，要经过哪些模块(比如执行load指令时)？

~~~
CPU 从内存中一条一条地取出指令和相应的数据，按指令操作码的规定，对数据进行运算处理，直到程序执行完毕为止。具体过程可分为以下四步：
1、取指令
2、指令译码
3、执行指令
4、修改指令计数器
~~~



#### 2、cpu访问内存速度是什么量级的

![image-20240313200112668](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20240313200112668.png)

~~~
	不同级别的存储结构对于CPU的访问速度是不同的。
	通常来说，CPU访问速度最快的是寄存器，其次是一级缓存（L1 Cache），二级缓存（L2 Cache），三级缓存（L3 Cache），最后是主存储器（DRAM）。
	1、寄存器是CPU内部的存储器，访问速度非常快，可以在一个CPU周期内完成访问。
	2、一级缓存（L1 Cache）是CPU内部的缓存，访问速度也非常快，通常可以在一个CPU周期内完成访问。
	3、二级缓存（L2 Cache）和三级缓存（L3 Cache）是位于CPU和主存储器之间的缓存，访问速度比主存储器快很多，但比L1 Cache慢一些。
	4、主存储器（DRAM）是CPU访问速度最慢的存储结构，访问速度通常需要几十个CPU周期。因此，在程序设计中，应尽可能地利用寄存器和缓存，以减少对主存储器的访问，从而提高程序的执行效率

~~~



#### 3、cpu访问内存的过程是什么样的

~~~
对于一个有MMU(内存管理单元)的CPU而言，MMU开启后，CPU是这样寻址的：CPU任何时候，一切时候，发出的地址都是虚拟地址，这个虚拟地址发给MMU后,MMU通过页表来在页表里面查出来这个虚拟地址对应的物理地址是什么，从而去访问外面的内存条。MMU里面的页表地址寄存器，记录了页表本身的存放位置。
~~~

![image-20240313213204963](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20240313213204963.png)



https://www.eet-china.com/mp/a265006.html

```
假设虚拟内存地址是32位：
虚拟地址高20位：页表地址
虚拟地址低12位：页内偏移
任何一个虚拟地址，都可以用地址的高20位（由于一页是4KB，低12位就是叶内偏移了），作为页表这个表的行号去读对应的页表项。
```



#### 4、介绍一下cpu中的cache

```
	cpu中的cache是用于减少[处理器]访问内存所需平均时间的部件。速度仅次于cpu中的寄存器
	当处理器发出内存访问请求时，会先查看缓存内是否有请求数据。如果存在（命中），则不经访问内存直接返回该数据；如果不存在（失效），则要先把内存中的相应数据载入缓存，再将其返回处理器。
	缓存之所以有效，主要是因为程序运行时对内存的访问呈现局部性（Locality）特征。这种局部性既包括空间局部性（Spatial Locality），也包括时间局部性（Temporal Locality）。有效利用这种局部性，缓存可以达到极高的命中率。
```



#### 5、讲讲cache和buffer

~~~
1）buffer（缓冲）是为了提高内存和硬盘（或其他I/O设备）之间的数据交换的速度而设计的。

2）cache（缓存）是为了提高cpu和内存之间的数据交换速度而设计的，也就是平常见到的一级缓存、二级缓存、三级缓存。 cpu在执行程序所用的指令和读数据都是针对内存的，也就是从内存中取得的。由于内存读写速度慢，为了提高cpu和内存之间数据交换的速度，在cpu和内存之间增加了cache，它的速度比内存快，但是造价高，又由于在cpu内不能集成太多集成电路，所以一般cache比较小，以后intel等公司为了进一步提高速度，又增加了二级cache，甚至三级cache，它是根据程序的局部性原理而设计的，就是cpu执行的指令和访问的数据往往在集中的某一块，所以把这块内容放入cache后，cpu就不用在访问内存了，这就提高了访问速度。当然若cache中没有cpu所需要的内容，还是要访问内存的。
3）总结：
数据写入内存空间，这段空间就是缓冲区buffer，写入缓冲区
把数据从内存空间读出，这段空间就是缓存器cache，读取缓存区
~~~



#### 6、通过什么方式写出对cache更友好的代码？对于数组，某些特定的长度会使读取变慢吗？

~~~
	CPU缓存会把一片连续的内存空间读入，因为数组结构是连续的内存地址，所以数组全部或者部分元素被连续存在CPU缓存里面，平均读取每个元素的时间只要3个CPU时钟周期。  
	而链表的节点是分散在堆空间里面的，这时候CPU缓存帮不上忙，只能是去读取内存，平均读取时间需要100个CPU时钟周期。这样算下来，数组访问的速度比链表快33倍！（这里只是介绍概念，具体的数字因CPU而异）
	程序中尽量使用连续的数据结构，这样可以充分发挥CPU缓存的威力
~~~



#### 7、你知道虚拟内存吗？好处是什么？每个页的大小一般是多少？

~~~
每个进程都有自己的进程地址空间，虚拟内存可以控制进程对物理内存的访问，隔离不同进程的访问权限，提高系统的安全性
虚拟内存是操作系统物理内存和进程之间的中间层，它为进程隐藏了物理内存这一概念，为进程提供了更加简洁和易用的接口以及更加复杂的功能。
好处：
1、虚拟内存可以结合磁盘和物理内存的优势为进程提供看起来速度足够快并且容量足够大的存储
2、虚拟内存可以为进程提供独立的内存空间并引入多层的页表结构将虚拟内存翻译为物理内存，进程之间可以互相共享物理内存减少开销，也能简化程序的链接、装载以及内存分配过程
3、虚拟内存可以控制进程对物理内存的访问、隔离不同进程的访问权限，提高系统的安全性

每一个页一般4KB，32位的虚拟地址为例，高地址20位存放页表地址，低12位存放页内偏移
为什么是4K？因为要和物理内存保持一致
内核会将整个物理内存空间划分为一页一页大小相同的的内存块，每个内存块大小为 4K，称为一个物理内存页。
~~~



#### 8、页表内容，TLB，多级页表，页表是属于进程的吗，进程切换过程，页表地址是物理还是虚拟？

https://www.cnblogs.com/binlovetech/p/17571929.html

​		每创建一个进程，都会创建一个PCB，一个虚拟地址空间，一个页表，一块物理空间，

- ```
  页表是一种特殊的数据结构放在系统空间的页表区，存放逻辑页与物理页帧的对应关系。 每一个进程都拥有一个自己的页表，PCB表中有指针指向页表。
  页表内容：内核会在页表中划分出来一个个大小相等的小内存块，这些小内存块我们称之为页表项 PTE（Page Table Entry），正是这个 PTE 保存了进程虚拟内存空间中的虚拟页与物理内存页的映射关系，以及控制物理内存访问的相关权限位。
  ```

- ```
  TLB: 转换后援缓冲器，TLB本质上就是一个cache，是用来加速页表查找的
  ```

- ```
  在Linux中，进程操作的都是虚拟地址，而MMU（内存管理单元）是进行虚拟地址与物理地址的转化，TLB用于加快虚拟地址（线性地址）的转换，每个进程都有自己对应的页表，不同进程相同的虚拟地址映射的大概率不是相同的物理地址，同时不同进程不同的虚拟地址可能映射到相同的物理地址上。
  ```

- ```、
  内核页表一般指的是内核地址空间的页表，用户页表表示用户地址空间的。
  用32位操作系统作为例子，虽然操作系统有N个进程，每个进程都有各自页表，但内核的页表只有一个。当发生进程切换时，只有用户页表被切换走，内核页表并不改变。
  ```

- ```
  内核从物理内存空间中拿出一个物理内存页来专门存储进程里的这些内存映射关系，而这种物理内存页我们将其称之为页表，从这里可以看出页表的本质其实就是一个物理内存页
  ```

  

#### 9、线程和进程的区别？他们在linux上实现的区别？

https://blog.csdn.net/Abysscarry/article/details/103844087

- **功能**： 进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位

- **开销**： 每个进程都有独立的内存空间，存放代码和数据段等，程序之间的切换会有较大的开销；线程可以看做轻量级的进程，共享内存空间，每个线程都有自己独立的运行栈和程序计数器，线程之间切换的开销小。

- **运行环境**： 在操作系统中能同时运行多个进程；而在同一个进程（程序）中有多个线程同时执行（通过CPU调度，在每个时间片中只有一个线程执行）

- **创建过程**： 在创建新进程的时候，会将父进程的所有五大数据结构复制新的，形成自己新的内存空间数据，而在创建新线程的时候，则是引用进程的五大数据结构数据，但是线程会有自己的私有数据、栈空间。

进程和线程其实在cpu看来都是task_struct结构的一个封装，执行不同task即可，而且在cpu看来就是在执行这些task时候遵循对应的调度策略以及上下文资源切换定义，包括寄存器地址切换，内核栈切换。所以对于cpu而言，进程和线程是没有区别的。


#### 10、缓存，缓存一致性，MESI

https://www.xiaolincoding.com/os/1_hardware/cpu_mesi.html#%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98

~~~
缓存一致性：两个CPU执行两个线程的任务，其中一个线程修改了变量的值，写入了缓存，而缓存里的值还没有写入内存，另一个线程去取变量的值时，变量的值不正确，
A 号核心和 B 号核心的缓存，在这个时候是不一致，从而会导致执行结果的错误。
要解决缓存一致性的问题，就需要一种机制，来同步两个不同核心里面的缓存数据。要实现的这个机制的话，要保证做到下面这 2 点：
第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为写传播（Write Propagation）；
第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为事务的串行化（Transaction Serialization）。
~~~





#### 11、问了debug工具

​	gdb

#### 12、C++服务异常怎么排查



#### 13、linux查看网络状态，查看文件第三列

​	netstat

#### 14、C++性能监测，用过哪些工具，prof

| gprof    | 获取每个函数的调用次数以及运行时间         | 无需安装，GUN自带；使用方便 | 不适用于多线程程序以及function pointers；可视化工具一般；软件本身好像不是用来做性能分析的 |
| -------- | ------------------------------------------ | --------------------------- | ------------------------------------------------------------ |
| valgrind | 除了查看，还有很多其他工具（内存泄漏啥的） | 功能全；可视化工具完善      | 运行速度特别慢（比普通程序慢10倍很正常）；由于功能太多，学习成本较高 |

| gperftools | 查找程序运行热点（不能知道单个函数单次运行时间，而是获得每个函数运行时间占整体的百分比） | 使用方便，对程序整体速度影响小                               | 功能单一（其他的都好像能做别的事情）；可视化工具一般 |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------------------------- |
| perf       | 类似 gperftools，不过针对的是整体Linux内核；功能强大         | 内核工具，不仅可用来分析单个程序，还可用来分析整机性能；可视化工具很好看；功能完善 | 函数名有很多 Unknown，当前函数感觉函数名看不懂       |

#### 15、gdb看backtrace，切换线程

~~~~
gdb ./main
bt
进程切换：
info inferiors					查看当前所有进程
inferiors <num>					切换当前GDB调试进程，其中num为上一条指令中列出的进程Num
线程切换：
info threads					查看线程数
thread <num>					切换线程，num为上一条指令给出的
break line thread threadNo		其中line为你的源码行数，threadNo为info threads命令中GDB给出的线程ID，若不指定threadNo，则为所有线程打断点。

在多线程调试时，可以设置其余线程的阻塞状态
show scheduler-locking			查看设置
set scheduler-locking <on><off><step>
    on							表示调试线程执行时，其余线程锁定，阻塞等待，
    off 						表示不锁定其他线程
    step 						表示在step（单步）调试时，只有当前线程运行

~~~~



#### 16、说一下系统的进程调度机制

~~~·
非抢占式调度算法：该算法挑选一个进程，让该进程运行直到被阻塞或者进程退出，才会调用另外一个进程，不会理会时钟中断
抢占式调度算法：该算法挑选一个进程，让该进程在某个时间段内运行，如果运行超出该时间段，则会把他挂起，接着调度程序从就绪队列中挑选另一个进程运行。这种抢占式调度需要在时间段结束时发生时钟中断，以便把CPU控制权返回给调度程序进行调度。这就是常说的时间片机制。
调度算法：
先来先服务：
最短作业优先调度（SJF）算法
时间片轮转（RR）调度算法
最高优先级（HPF）调度算法
~~~



#### 17、进程间通信的方法

~~~
1、管道
2、消息队列
3、共享内存
4、信号量
5、信号
6、socket

~~~



#### 18、线程继承了进程的哪些资源

~~~
进程中的所有信息对该进程的所有线程都是共享的；
可执行的程序文本；
程序的全局内存；
堆内存；
栈；
文件描述符表；创建子线程前打开的文件将共享读写位置，即共享打开文件表项，创建之后各自打开不共享共享读写位置 即不共享打开文件表项，父子进程一样。
信号的处理是进程中所有线程共享的

线程特有的：(线程上下文)
线程ID
程序计数器（存放cpu执行的指令）
一组寄存器值
独立的栈区
调度优先级和策略
信号屏蔽字
线程私有数据
~~~



#### 19、线程是如何切换的

~~~
1、挂起当前线程，将这个任务在 CPU 中的状态（上下文）存储于内存中的某处
2、恢复一个线程，在内存中检索下一个任务的上下文并将其在 CPU 的寄存器中恢复
3、跳转到程序计数器所指向的位置（即跳转到任务被中断时的代码行），以恢复该进程在程序中
开销：
直接消耗：指的是CPU寄存器需要保存和加载, 系统调度器的代码需要执行, TLB实例需要重新加载, CPU 的pipeline需要刷掉
间接消耗：指的是多核的cache之间得共享数据, 间接消耗对于程序的影响要看线程工作区操作数据的大小
	直接开销就是在切换时，cpu必须做的事情，包括：
        1、切换页表全局目录
        2、切换内核态堆栈
        3、切换硬件上下文（进程恢复前，必须装入寄存器的数据统称为硬件上下文）
            ip(instruction pointer)：指向当前执行指令的下一条指令
            bp(base pointer): 用于存放执行中的函数对应的栈帧的栈底地址
            sp(stack poinger): 用于存放执行中的函数对应的栈帧的栈顶地址
            cr3:页目录基址寄存器，保存页目录表的物理地址
            ......
        4、刷新TLB (Translation Lookaside Buffer 转译后备缓冲器，也被翻译为页表缓存、转址旁路缓存，为CPU的一种缓存，由存储器管理单元用于改进虚拟地址到物理地址的转译速度。)
        5、系统调度器的代码执行
	间接开销主要指的是虽然切换到一个新进程后，由于各种缓存并不热，速度运行会慢一些。如果进程始终都在一个CPU上调度还好一些，如果跨CPU的话，之前热起来的TLB、L1、L2、L3因为运行的进程已经变了，所以以局部性原理cache起来的代码、数据也都没有用了，导致新进程穿透到内存的IO会变多。 其实我们上面的实验并没有很好地测量到这种情况，所以实际的上下文切换开销可能比3.5us要大。
~~~



#### 20、怎么保证线程安全

~~~
锁，条件变量
~~~



#### 21、ls命令的执行的底层，用了什么系统调用，是如何进行进程间切换的

~~~
	ls 命令实际上是通过系统调用（system call）来获取当前目录中的文件列表信息。当我们执行 ls 命令时，操作系统内核会将当前目录的相关信息加载到内存中，并执行相应的系统调用来获取文件列表信息。系统调用会在文件系统中遍历目录，并读取目录中的文件名、文件类型、权限等信息，并将它们传递给 ls 命令进行显示。
~~~



## 网络

#### 1、三次握手

![image-20240314100540072](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20240314100540072.png)

#### 2、tcp与udp的区别

~~~
1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接
2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付
3、TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）
4、每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信
5、TCP首部开销20字节;UDP的首部开销小，只有8个字节
6、TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道
~~~



#### 3、计网，网络五层协议栈层次，socket在哪一层？

~~~
Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口
~~~



#### 4、tcp和udp在理想情况下谁更快，为什么

~~~
UDP比TCP更快，但也更容易出错。原因是UDP不像TCP那样对数据包进行严格的检查，而是采用更连续的数据流。 
~~~



#### 5、为什么udp头部需要封装长度信息

~~~
	第一种说法：因为为了网络设备硬件设计和处理方便，首部长度需要是 4 字节的整数倍。如果去掉 UDP 的「包长度」字段，那 UDP 首部长度就不是 4 字节的整数倍了，所以我觉得这可能是为了补全 UDP 首部长度是 4 字节的整数倍，才补充了「包长度」字段。
	第二种说法：如今的 UDP 协议是基于 IP 协议发展的，而当年可能并非如此，依赖的可能是别的不提供自身报文长度或首部长度的网络层协议，因此 UDP 报文首部需要有长度字段以供计算。
~~~

tcp头部：

![image-20240314094820763](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20240314094820763.png)

udp头部信息：

![image-20240314094845698](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20240314094845698.png)



#### 6、HTTP1.0和2.0的区别

#### 7、TCP为什么是可靠的，UDP为什么是不可靠的

~~~
TCP可靠：连接管理(三次握手，四次挥手)，校验和，序列号，确认应答，超时重传，流量控制，拥塞控制

UDP不可靠：主要原因是因为它没有提供传输层的可靠性保证，也就是说，在数据传输过程中，UDP协议并不会对数据包的完整性、可靠性和时序性进行检测和保证。 UDP数据包在传输过程中，可能会丢失、重复、交错或者无序，甚至UDP协议本身也无法保证接收方能够收到发送方发送的所有数据包。
~~~



#### 8、TCP是怎么保证有序序列的

~~~
序列号：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来解决网络包乱序问题。
~~~

#### 9、TCP怎么解决丢包的问题

~~~
确认应答号：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题
~~~



#### 9、什么是粘包问题，为什么会发生

~~~
粘包：在进行数据传输时，发送端一次性连续发送多个数据包，TCP 协议将多个数据包打包成一个 TCP 报文发送出去；

拆包：当发送端发送的数据包长度超过一次 TCP 报文所能传输的最大值时，就会将该数据包拆分成多个 TCP 报文分开传输。
~~~

#### 10、如何解决粘包和拆包问题？

~~~
（1）设置消息定长
（2）头部添加消息长度
（3）消息尾部添加特殊字符进行分割
（4）将消息分为消息头和消息尾。
~~~

#### 11、什么是MTU，MSS

~~~
MTU：一个网络包的最大长度，以太网中一般为 1500 字节；
MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；
~~~



#### 12、什么是长连接，什么是短连接

- 长连接：client方与server方先建立连接，连接建立后不断开，然后再进行报文发送和接收。
  这种方式下由于通讯连接一直存在

  ​	建立连接——数据传输…（保持连接）…数据传输——关闭连接

- 短连接：Client方与server每进行一次报文收发交易时才进行通讯连接，交易完毕后立即断开连接。

  ​	建立连接——数据传输——关闭连接…建立连接——数据传输——关闭连接

- tcp中长连接怎么实现的：

  ~~~
  tcp的保活机制（内核进行keepalive探测）：
  	1、如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。
  	2、如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。
  	3、如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。
  ~~~

  ~~~
  开启keepalive
  //on 是 1 表示打开 keepalive 选项，为 0 表示关闭，0 是默认值
   int on = 1;
   setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, &on, sizeof(on));
   //发送 keepalive 报文的时间间隔
   int val = 7200;
   setsockopt(fd, IPPROTO_TCP, TCP_KEEPIDLE, &val, sizeof(val));
   ​
   //两次重试报文的时间间隔
   int interval = 75;
   setsockopt(fd, IPPROTO_TCP, TCP_KEEPINTVL, &interval, sizeof(interval));
   ​
   int cnt = 9;
   setsockopt(fd, IPPROTO_TCP, TCP_KEEPCNT, &cnt, sizeof(cnt));
   TCP_KEEPIDLE 选项设置了发送 keepalive 报文的时间间隔，发送时如果对端回复 ACK。则本端 TCP 协议栈认为该连接依然存活，继续等 7200 秒后再发送 keepalive 报文；如果对端回复 RESET，说明对端进程已经重启，本端的应用程序应该关闭该连接。
  
  如果对端没有任何回复，则本端做重试，如果重试 9 次（TCP_KEEPCNT 值）（前后重试间隔为 75 秒（TCP_KEEPINTVL 值））仍然不可达，则向应用程序返回 ETIMEOUT（无任何应答）或 EHOST 错误信息。
  ~~~

  我们可以使用如下命令查看 Linux 系统上的上述三个值的设置情况：

  ~~~
  [root@iZ238vnojlyZ ~]# sysctl -a | grep keepalive
   net.ipv4.tcp_keepalive_intvl = 75
   net.ipv4.tcp_keepalive_probes = 9
   net.ipv4.tcp_keepalive_time = 7200
  ~~~

  [TCP中已有SO_KEEPALIVE选项，为什么还要在应用层加入心跳包机制？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/389090880)



